{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9a0792-db34-4cc0-95da-29ed094205f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116446/3954359919.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
     ]
    }
   ],
   "source": [
    "#jupyter labextension install jupyterlab-plotly\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns # for statistical data visualization\n",
    "%matplotlib inline\n",
    "from ExKMC.Tree import Tree\n",
    "from IPython.display import Image\n",
    "\n",
    "np.random.seed(1)\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "import shap\n",
    "import joblib as jbl\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import kaleido\n",
    "import os\n",
    "import img2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da87c6b9-c554-4929-b3cf-bdd83e20f273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>methodAnonymousClassesQty</th>\n",
       "      <th>methodAssignmentsQty</th>\n",
       "      <th>methodCbo</th>\n",
       "      <th>methodComparisonsQty</th>\n",
       "      <th>methodLambdasQty</th>\n",
       "      <th>methodLoc</th>\n",
       "      <th>methodLoopQty</th>\n",
       "      <th>methodMathOperationsQty</th>\n",
       "      <th>methodMaxNestedBlocks</th>\n",
       "      <th>methodNumbersQty</th>\n",
       "      <th>...</th>\n",
       "      <th>methodRfc</th>\n",
       "      <th>methodStringLiteralsQty</th>\n",
       "      <th>methodSubClassesQty</th>\n",
       "      <th>methodTryCatchQty</th>\n",
       "      <th>methodUniqueWordsQty</th>\n",
       "      <th>methodVariablesQty</th>\n",
       "      <th>methodWmc</th>\n",
       "      <th>bugFixCount</th>\n",
       "      <th>refactoringsInvolved</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52702</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057847</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973440</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851919</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884029</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         methodAnonymousClassesQty  methodAssignmentsQty  methodCbo  \\\n",
       "id_                                                                   \n",
       "27308                            0                     0          0   \n",
       "19994                            0                    10          1   \n",
       "29413                            0                     2          5   \n",
       "52702                            0                    23         11   \n",
       "41416                            0                     0          1   \n",
       "...                            ...                   ...        ...   \n",
       "397                              0                     0          4   \n",
       "1057847                          1                     0          3   \n",
       "973440                           0                     1          3   \n",
       "851919                           0                     0          3   \n",
       "884029                           0                     5          7   \n",
       "\n",
       "         methodComparisonsQty  methodLambdasQty  methodLoc  methodLoopQty  \\\n",
       "id_                                                                         \n",
       "27308                       0                 0          3              0   \n",
       "19994                       0                 0         25              2   \n",
       "29413                       0                 0         15              0   \n",
       "52702                       2                 0         57              2   \n",
       "41416                       0                 0          4              0   \n",
       "...                       ...               ...        ...            ...   \n",
       "397                         0                 0          3              0   \n",
       "1057847                     0                 0         13              0   \n",
       "973440                      0                 0          3              1   \n",
       "851919                      0                 0          4              0   \n",
       "884029                      2                 0         39              0   \n",
       "\n",
       "         methodMathOperationsQty  methodMaxNestedBlocks  methodNumbersQty  \\\n",
       "id_                                                                         \n",
       "27308                          0                      0                 0   \n",
       "19994                          2                      3                 0   \n",
       "29413                          0                      2                 0   \n",
       "52702                          1                      3                 4   \n",
       "41416                          0                      0                 0   \n",
       "...                          ...                    ...               ...   \n",
       "397                            0                      0                 0   \n",
       "1057847                        0                      1                 0   \n",
       "973440                         0                      0                 1   \n",
       "851919                         0                      0                 0   \n",
       "884029                         5                      3                 0   \n",
       "\n",
       "         ...  methodRfc  methodStringLiteralsQty  methodSubClassesQty  \\\n",
       "id_      ...                                                            \n",
       "27308    ...          0                        0                    0   \n",
       "19994    ...          8                        7                    0   \n",
       "29413    ...          8                        1                    0   \n",
       "52702    ...         34                        1                    0   \n",
       "41416    ...          1                        0                    0   \n",
       "...      ...        ...                      ...                  ...   \n",
       "397      ...          0                        1                    0   \n",
       "1057847  ...          0                        0                    0   \n",
       "973440   ...          5                        0                    0   \n",
       "851919   ...          2                        0                    0   \n",
       "884029   ...         14                        8                    0   \n",
       "\n",
       "         methodTryCatchQty  methodUniqueWordsQty  methodVariablesQty  \\\n",
       "id_                                                                    \n",
       "27308                    0                     4                   0   \n",
       "19994                    0                    32                   8   \n",
       "29413                    1                    16                   1   \n",
       "52702                    0                    59                  14   \n",
       "41416                    0                     6                   0   \n",
       "...                    ...                   ...                 ...   \n",
       "397                      0                    13                   0   \n",
       "1057847                  0                    10                   0   \n",
       "973440                   0                    10                   1   \n",
       "851919                   0                     9                   0   \n",
       "884029                   1                    51                   3   \n",
       "\n",
       "         methodWmc  bugFixCount  refactoringsInvolved  y  \n",
       "id_                                                       \n",
       "27308            1            0                     0  1  \n",
       "19994            6            3                     5  1  \n",
       "29413            3            1                     1  1  \n",
       "52702           13            4                    10  1  \n",
       "41416            2            9                     1  1  \n",
       "...            ...          ...                   ... ..  \n",
       "397              1            0                     7  0  \n",
       "1057847          1            0                     0  0  \n",
       "973440           3           26                     9  0  \n",
       "851919           1            1                    13  0  \n",
       "884029          10            3                     3  0  \n",
       "\n",
       "[150000 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Generating 150k Dataset with random instances from yes and no datasets\n",
    "# path_datasets = \"../datasets/\"\n",
    "# data_yes = pd.read_csv(path_datasets+\"Dataset_99k_yes.csv\")\n",
    "# data_no = pd.read_csv(path_datasets+\"Dataset_75k_no.csv\")\n",
    "\n",
    "# data_yes = data_yes.set_index(\"id_\")\n",
    "# data_no = data_no.rename(columns={\"id\": \"id_\"})\n",
    "# data_no = data_no.set_index(\"id_\")\n",
    "\n",
    "# sample_data_yes = data_yes.sample(n=75000)\n",
    "# sample_data_no = data_no.sample(n=75000)\n",
    "\n",
    "# training_samples = pd.concat([sample_data_yes, sample_data_no], axis=0)\n",
    "# display(training_samples)\n",
    "# training_samples.to_csv(path_datasets+\"Random_Generated_Dataset_150k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3a2871-07a8-4450-8c68-2404021e73ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>methodAnonymousClassesQty</th>\n",
       "      <th>methodAssignmentsQty</th>\n",
       "      <th>methodCbo</th>\n",
       "      <th>methodComparisonsQty</th>\n",
       "      <th>methodLambdasQty</th>\n",
       "      <th>methodLoc</th>\n",
       "      <th>methodLoopQty</th>\n",
       "      <th>methodMathOperationsQty</th>\n",
       "      <th>methodMaxNestedBlocks</th>\n",
       "      <th>methodNumbersQty</th>\n",
       "      <th>...</th>\n",
       "      <th>methodRfc</th>\n",
       "      <th>methodStringLiteralsQty</th>\n",
       "      <th>methodSubClassesQty</th>\n",
       "      <th>methodTryCatchQty</th>\n",
       "      <th>methodUniqueWordsQty</th>\n",
       "      <th>methodVariablesQty</th>\n",
       "      <th>methodWmc</th>\n",
       "      <th>bugFixCount</th>\n",
       "      <th>refactoringsInvolved</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52702</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057847</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973440</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851919</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884029</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         methodAnonymousClassesQty  methodAssignmentsQty  methodCbo  \\\n",
       "id_                                                                   \n",
       "27308                            0                     0          0   \n",
       "19994                            0                    10          1   \n",
       "29413                            0                     2          5   \n",
       "52702                            0                    23         11   \n",
       "41416                            0                     0          1   \n",
       "...                            ...                   ...        ...   \n",
       "397                              0                     0          4   \n",
       "1057847                          1                     0          3   \n",
       "973440                           0                     1          3   \n",
       "851919                           0                     0          3   \n",
       "884029                           0                     5          7   \n",
       "\n",
       "         methodComparisonsQty  methodLambdasQty  methodLoc  methodLoopQty  \\\n",
       "id_                                                                         \n",
       "27308                       0                 0          3              0   \n",
       "19994                       0                 0         25              2   \n",
       "29413                       0                 0         15              0   \n",
       "52702                       2                 0         57              2   \n",
       "41416                       0                 0          4              0   \n",
       "...                       ...               ...        ...            ...   \n",
       "397                         0                 0          3              0   \n",
       "1057847                     0                 0         13              0   \n",
       "973440                      0                 0          3              1   \n",
       "851919                      0                 0          4              0   \n",
       "884029                      2                 0         39              0   \n",
       "\n",
       "         methodMathOperationsQty  methodMaxNestedBlocks  methodNumbersQty  \\\n",
       "id_                                                                         \n",
       "27308                          0                      0                 0   \n",
       "19994                          2                      3                 0   \n",
       "29413                          0                      2                 0   \n",
       "52702                          1                      3                 4   \n",
       "41416                          0                      0                 0   \n",
       "...                          ...                    ...               ...   \n",
       "397                            0                      0                 0   \n",
       "1057847                        0                      1                 0   \n",
       "973440                         0                      0                 1   \n",
       "851919                         0                      0                 0   \n",
       "884029                         5                      3                 0   \n",
       "\n",
       "         ...  methodRfc  methodStringLiteralsQty  methodSubClassesQty  \\\n",
       "id_      ...                                                            \n",
       "27308    ...          0                        0                    0   \n",
       "19994    ...          8                        7                    0   \n",
       "29413    ...          8                        1                    0   \n",
       "52702    ...         34                        1                    0   \n",
       "41416    ...          1                        0                    0   \n",
       "...      ...        ...                      ...                  ...   \n",
       "397      ...          0                        1                    0   \n",
       "1057847  ...          0                        0                    0   \n",
       "973440   ...          5                        0                    0   \n",
       "851919   ...          2                        0                    0   \n",
       "884029   ...         14                        8                    0   \n",
       "\n",
       "         methodTryCatchQty  methodUniqueWordsQty  methodVariablesQty  \\\n",
       "id_                                                                    \n",
       "27308                    0                     4                   0   \n",
       "19994                    0                    32                   8   \n",
       "29413                    1                    16                   1   \n",
       "52702                    0                    59                  14   \n",
       "41416                    0                     6                   0   \n",
       "...                    ...                   ...                 ...   \n",
       "397                      0                    13                   0   \n",
       "1057847                  0                    10                   0   \n",
       "973440                   0                    10                   1   \n",
       "851919                   0                     9                   0   \n",
       "884029                   1                    51                   3   \n",
       "\n",
       "         methodWmc  bugFixCount  refactoringsInvolved  y  \n",
       "id_                                                       \n",
       "27308            1            0                     0  1  \n",
       "19994            6            3                     5  1  \n",
       "29413            3            1                     1  1  \n",
       "52702           13            4                    10  1  \n",
       "41416            2            9                     1  1  \n",
       "...            ...          ...                   ... ..  \n",
       "397              1            0                     7  0  \n",
       "1057847          1            0                     0  0  \n",
       "973440           3           26                     9  0  \n",
       "851919           1            1                    13  0  \n",
       "884029          10            3                     3  0  \n",
       "\n",
       "[150000 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing training dataset\n",
    "path_datasets = \"../datasets/\"\n",
    "training_samples = pd.read_csv(path_datasets+\"Random_Generated_Dataset_150k.csv\")\n",
    "data = training_samples.set_index(\"id_\")\n",
    "display(data)\n",
    "\n",
    "# splitting train and test\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# training random forest model\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X, y)\n",
    "\n",
    "# getting list of feature names\n",
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee79a861-c914-4c43-a06b-7dbfcff03718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up SHAP\n",
    "try:\n",
    "    with open(\"./\" + 'shap_explainer', 'rb') as f:\n",
    "        explainer_shap = jbl.load(f)\n",
    "except:\n",
    "    explainer_shap = shap.TreeExplainer(forest)\n",
    "    with open(\"./\" + 'shap_explainer', 'wb') as f:\n",
    "        jbl.dump(explainer_shap, f)\n",
    "\n",
    "# Setting up LIME\n",
    "explainer_lime = lime.lime_tabular.LimeTabularExplainer(X.values, feature_names=X.columns.values.tolist(), class_names=[0, 1], verbose=True, mode='classification',  discretize_continuous=True)\n",
    "\n",
    "# Setting up Anchors\n",
    "explainer_anchors = anchor_tabular.AnchorTabularExplainer(\n",
    "    [0, 1],\n",
    "    X.columns.values.tolist(),\n",
    "    X.values,\n",
    "    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54171a79-dc52-45dd-8b58-68ca153abd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# function to help sorting features\n",
    "def compare_shap_feature_weights(feature_value):\n",
    "    # highest weights first\n",
    "    return -feature_value['feature_weight']\n",
    "\n",
    "def scale_weights(features_weights, features_exp):\n",
    "    # scale weights to sum to 1\n",
    "    np_features_weights = np.asarray(features_weights)\n",
    "    scaled_features_weights = np_features_weights / np_features_weights.sum()\n",
    "    # add values to dict\n",
    "    for i in range(0, len(features_exp)):\n",
    "        features_exp[i]['feature_weight'] = scaled_features_weights[i]\n",
    "    return features_exp\n",
    "\n",
    "# export shap features' explanations\n",
    "def export_shap_exp(row, feature_names, shap_values, refactor_bool):\n",
    "    # get shap values to refactor instance\n",
    "    shap_values_to_refactor = shap_values[1]\n",
    "    shap_output = dict()\n",
    "    \n",
    "    features_exp = []\n",
    "    features_weights = []\n",
    "    for i in range(0, len(feature_names)):\n",
    "        condition = shap_values_to_refactor[i] > 0 if refactor_bool else shap_values_to_refactor[i] < 0\n",
    "        # shap_values has positive values (to refactor) and negative ones (not to refactor)\n",
    "        if condition:\n",
    "            f = dict()\n",
    "            feature_name = feature_names[i]\n",
    "            f['feature_name'] = feature_name\n",
    "            f['feature_value'] = int(row[feature_name])\n",
    "            features_weights.append(shap_values_to_refactor[i])\n",
    "            f['feature_ranges'] = None\n",
    "            features_exp.append(f)\n",
    "    # scale weights to sum to 1\n",
    "    scaled_features_exp = scale_weights(features_weights, features_exp)\n",
    "    # sort features by feature weight\n",
    "    sorted_features_exp = sorted(scaled_features_exp, key=compare_shap_feature_weights)\n",
    "    # append feature ranking after sort\n",
    "    rank = 1\n",
    "    for f in sorted_features_exp:\n",
    "        f['feature_rank'] = rank\n",
    "        rank += 1\n",
    "    shap_output['features'] = sorted_features_exp\n",
    "    return shap_output\n",
    "\n",
    "# export lime features' explanations\n",
    "def export_lime_exp(row, feature_names, exp_lime, refactor_bool):\n",
    "    lime_output = dict()\n",
    "    # general instance indices\n",
    "    lime_output['intercept'] = exp_lime.intercept[1]\n",
    "    lime_output['local_prediction'] = exp_lime.local_pred[0]\n",
    "    lime_features = exp_lime.as_list()\n",
    "    # features' values\n",
    "    features_exp = []\n",
    "    features_weights = []\n",
    "    rank = 1\n",
    "    for value in lime_features:\n",
    "        condition = value[1] > 0 if refactor_bool else value[1] < 0\n",
    "        # value[1] (feature_weight) has positive values (to refactor) and negative ones (not to refactor)\n",
    "        if condition:\n",
    "            f = dict()\n",
    "            # extract feature name from feature ranges string\n",
    "            any((feature_name := substring) in value[0] for substring in feature_names)\n",
    "            f['feature_name'] = feature_name\n",
    "            f['feature_value'] = int(row[feature_name])\n",
    "            features_weights.append(value[1])\n",
    "            f['feature_ranges'] = value[0]\n",
    "            f['feature_rank'] = rank # feature's order of priority in explainer's result\n",
    "            features_exp.append(f)\n",
    "            rank += 1\n",
    "    # scale weights to sum to 1\n",
    "    scaled_features_exp = scale_weights(features_weights, features_exp)\n",
    "    lime_output['features'] = scaled_features_exp\n",
    "    return lime_output\n",
    "\n",
    "# export anchors features' explanations\n",
    "def export_anchors_exp(row, feature_names, anchors_exp, refactor_bool):\n",
    "    anchors_output = dict()\n",
    "    # general instance indices\n",
    "    anchors_output['precision'] = anchors_exp.precision()\n",
    "    anchors_output['coverage'] = anchors_exp.coverage()\n",
    "    # features' values\n",
    "    features_exp = []\n",
    "    features_weights = []\n",
    "    rank = 1\n",
    "    for i in range(0, len(anchors_exp.names())):\n",
    "        f = dict()\n",
    "        # extract feature name from anchors' names string\n",
    "        any((feature_name := substring) in str(anchors_exp.names()[i]) for substring in feature_names)\n",
    "        f['feature_name'] = feature_name\n",
    "        f['feature_value'] = int(row[feature_name])\n",
    "        weight = (anchors_exp.precision(i)*anchors_exp.coverage(i))/anchors_exp.precision()\n",
    "        features_weights.append(weight)\n",
    "        f['feature_weight'] = None\n",
    "        f['feature_ranges'] = anchors_exp.names()[i]\n",
    "        f['feature_rank'] = rank # feature's order of priority in explainer's result\n",
    "        features_exp.append(f)\n",
    "        rank += 1\n",
    "    # scale weights to sum to 1\n",
    "    scaled_features_exp = scale_weights(features_weights, features_exp)\n",
    "    anchors_output['features'] = features_exp\n",
    "    return anchors_output\n",
    "\n",
    "def run_and_export_explainers(samples, i, refactor_bool):\n",
    "    feature_names = list(samples.columns)\n",
    "    \n",
    "    #SHAP\n",
    "    row = samples.iloc[i]\n",
    "    shap_values = explainer_shap.shap_values(row)\n",
    "    shap_output = export_shap_exp(row, feature_names, shap_values, refactor_bool)\n",
    "\n",
    "    #LIME\n",
    "    exp_lime = explainer_lime.explain_instance(samples.values[i], forest.predict_proba, num_features=8)\n",
    "    lime_output = export_lime_exp(row, feature_names, exp_lime, refactor_bool)\n",
    "\n",
    "    #ANCHORS\n",
    "    exp_anchors = explainer_anchors.explain_instance(samples.values[i], forest.predict, threshold=0.95)\n",
    "    anchors_output = export_anchors_exp(row, feature_names, exp_anchors, refactor_bool)\n",
    "    \n",
    "    return [shap_output, lime_output, anchors_output]\n",
    "\n",
    "def export_other_explanations(samples, indexes, json_name):\n",
    "    explanations = dict()\n",
    "    for i in range(0, len(samples)):\n",
    "        json_output = dict()\n",
    "        # gives values of random forest predictions\n",
    "        predict = forest.predict_proba(samples.iloc[[i]])[0]\n",
    "        json_output['forest_prediction'] = {'not to refactor': predict[0], 'refactor': predict[1]}\n",
    "        # var to indicate if instance must be refactored or not\n",
    "        refactor_bool = 1 if predict[1] >= 0.5 else 0\n",
    "        # calls funtions that run and export shap, lime and anchors explanations\n",
    "        json_output['shap'], json_output['lime'], json_output['anchors'] = run_and_export_explainers(samples, i, refactor_bool)\n",
    "        # puts explanations in each instance index\n",
    "        explanations[int(indexes[i])] = json_output\n",
    "    #export explanations to json file\n",
    "    path = \"other_approach_jsons\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file_name = f\"{path}/{json_name}_other_top_features_ranking.json\"\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        json.dump(explanations, outfile)\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15417acc-d8ed-4e45-abe6-8a502231c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_names(json_features):\n",
    "    extracted_feature_names = []\n",
    "    for f in json_features:\n",
    "        extracted_feature_names.append(f['feature_name'])\n",
    "    return extracted_feature_names\n",
    "\n",
    "def get_info_by_feature_name(exp_f, feature_name):\n",
    "    feature_obj = next(x for x in exp_f if x[\"feature_name\"] == feature_name)\n",
    "    return feature_obj['feature_value'], feature_obj['feature_weight'], feature_obj['feature_ranges'], feature_obj['feature_rank']\n",
    "\n",
    "def compare_feature_weights(feature_value, order):    \n",
    "    if order[0]['explainer'] in feature_value and order[1]['explainer'] in feature_value and order[2]['explainer'] in feature_value:\n",
    "        return feature_value[order[0]['explainer']], feature_value[order[1]['explainer']], feature_value[order[2]['explainer']]\n",
    "    elif order[0]['explainer'] in feature_value and order[1]['explainer'] in feature_value:\n",
    "        return feature_value[order[0]['explainer']], feature_value[order[1]['explainer']]\n",
    "    elif order[0]['explainer'] in feature_value and order[2]['explainer'] in feature_value:\n",
    "        return feature_value[order[0]['explainer']], feature_value[order[2]['explainer']]\n",
    "    elif order[1]['explainer'] in feature_value and order[2]['explainer'] in feature_value:\n",
    "        return feature_value[order[1]['explainer']], feature_value[order[2]['explainer']]\n",
    "\n",
    "def combine_feature_explanations(feature_names, instance, priority_order):\n",
    "    sum_priority_order = 0\n",
    "    for p in priority_order:\n",
    "        sum_priority_order = sum_priority_order + priority_order[p]['priority_weight']\n",
    "        \n",
    "    shap_f = instance['shap']['features']\n",
    "    lime_f = instance['lime']['features']\n",
    "    anchors_f = instance['anchors']['features']\n",
    "\n",
    "    shap_f_names = extract_feature_names(shap_f)\n",
    "    lime_f_names = extract_feature_names(lime_f)\n",
    "    anchors_f_names = extract_feature_names(anchors_f)\n",
    "\n",
    "    combine_all, combine_shap_lime, combine_shap_anchors, combine_lime_anchors = ([] for i in range(4))\n",
    "    compiled_combinations = dict()\n",
    "    for f in feature_names:\n",
    "        # for each configuration of combination, gets feature name and explainers ranking\n",
    "        # when finds feature in shap, lime and anchors\n",
    "        if f in shap_f_names and f in lime_f_names and f in anchors_f_names:\n",
    "            feature_summary = dict()\n",
    "            feature_summary['feature_name'] = f\n",
    "            # get info from explainers' features\n",
    "            feature_value, anchors_weight, anchors_ranges, anchors_rank = get_info_by_feature_name(anchors_f, f)\n",
    "            _, shap_weight, _, shap_rank = get_info_by_feature_name(shap_f, f)\n",
    "            _, lime_weight, lime_ranges, lime_rank = get_info_by_feature_name(lime_f, f)\n",
    "            # feature value\n",
    "            feature_summary['feature_value'] = feature_value\n",
    "            # puts in dictionary\n",
    "            feature_summary['rank_anchors'] = anchors_rank\n",
    "            feature_summary['rank_shap'] = shap_rank\n",
    "            feature_summary['rank_lime'] = lime_rank\n",
    "            feature_summary['weight_anchors'] = anchors_weight\n",
    "            feature_summary['weight_shap'] = shap_weight\n",
    "            feature_summary['weight_lime'] = lime_weight\n",
    "            feature_summary['avg_weight'] = (2*shap_weight+lime_weight+3*anchors_weight)/6\n",
    "            feature_summary['range_anchors'] = anchors_ranges\n",
    "            feature_summary['range_lime'] = lime_ranges\n",
    "            feature_summary['agreement_index'] = (priority_order[0]['priority_weight']+priority_order[1]['priority_weight']+priority_order[2]['priority_weight'])/sum_priority_order\n",
    "            combine_all.append(feature_summary)\n",
    "        # when finds feature in shap and lime\n",
    "        elif f in shap_f_names and f in lime_f_names:\n",
    "            feature_summary = dict()\n",
    "            feature_summary['feature_name'] = f\n",
    "            # get info from explainers' features\n",
    "            feature_value, shap_weight, _, shap_rank = get_info_by_feature_name(shap_f, f)\n",
    "            _, lime_weight, lime_ranges, lime_rank = get_info_by_feature_name(lime_f, f)\n",
    "            # feature value\n",
    "            feature_summary['feature_value'] = feature_value\n",
    "            # puts in dictionary\n",
    "            feature_summary['rank_shap'] = shap_rank\n",
    "            feature_summary['rank_lime'] = lime_rank\n",
    "            feature_summary['weight_shap'] = shap_weight\n",
    "            feature_summary['weight_lime'] = lime_weight\n",
    "            feature_summary['avg_weight'] = (2*shap_weight+lime_weight)/3\n",
    "            feature_summary['range_lime'] = lime_ranges\n",
    "            feature_summary['agreement_index'] = (priority_order[1]['priority_weight']+priority_order[2]['priority_weight'])/sum_priority_order\n",
    "            combine_shap_lime.append(feature_summary)\n",
    "        # when finds feature in shap and anchors\n",
    "        elif f in shap_f_names and f in anchors_f_names:\n",
    "            feature_summary = dict()\n",
    "            feature_summary['feature_name'] = f\n",
    "            # get info from explainers' features\n",
    "            feature_value, anchors_weight, anchors_ranges, anchors_rank = get_info_by_feature_name(anchors_f, f)\n",
    "            _, shap_weight, _, shap_rank = get_info_by_feature_name(shap_f, f)\n",
    "            # feature value\n",
    "            feature_summary['feature_value'] = feature_value\n",
    "            # puts in dictionary\n",
    "            feature_summary['rank_anchors'] = anchors_rank\n",
    "            feature_summary['rank_shap'] = shap_rank\n",
    "            feature_summary['weight_anchors'] = anchors_weight\n",
    "            feature_summary['weight_shap'] = shap_weight\n",
    "            feature_summary['avg_weight'] = (2*shap_weight+3*anchors_weight)/5\n",
    "            feature_summary['range_anchors'] = anchors_ranges\n",
    "            feature_summary['agreement_index'] = (priority_order[0]['priority_weight']+priority_order[1]['priority_weight'])/sum_priority_order\n",
    "            combine_shap_anchors.append(feature_summary)\n",
    "        # when finds feature in lime and anchors\n",
    "        elif f in lime_f_names and f in anchors_f_names:\n",
    "            feature_summary = dict()\n",
    "            feature_summary['feature_name'] = f\n",
    "            # get info from explainers' features\n",
    "            feature_value, anchors_weight, anchors_ranges, anchors_rank = get_info_by_feature_name(anchors_f, f)\n",
    "            _, lime_weight, lime_ranges, lime_rank = get_info_by_feature_name(lime_f, f)\n",
    "            # feature value\n",
    "            feature_summary['feature_value'] = feature_value\n",
    "            # puts in dictionary\n",
    "            feature_summary['rank_anchors'] = anchors_rank\n",
    "            feature_summary['rank_lime'] = lime_rank\n",
    "            feature_summary['weight_anchors'] = anchors_weight\n",
    "            feature_summary['weight_lime'] = lime_weight\n",
    "            feature_summary['avg_weight'] = (lime_weight+3*anchors_weight)/4\n",
    "            feature_summary['range_anchors'] = anchors_ranges\n",
    "            feature_summary['range_lime'] = lime_ranges\n",
    "            feature_summary['agreement_index'] = (priority_order[0]['priority_weight']+priority_order[2]['priority_weight'])/sum_priority_order\n",
    "            combine_lime_anchors.append(feature_summary)\n",
    "\n",
    "    # order each list by importance (1st anchors, 2nd shap, 3rd lime)\n",
    "    compiled_combinations['combine_all'] = sorted(combine_all, key=lambda feature_value: compare_feature_weights(feature_value, priority_order))\n",
    "    compiled_combinations['combine_shap_lime'] = sorted(combine_shap_lime, key=lambda feature_value: compare_feature_weights(feature_value, priority_order))\n",
    "    compiled_combinations['combine_shap_anchors'] = sorted(combine_shap_anchors, key=lambda feature_value: compare_feature_weights(feature_value, priority_order))\n",
    "    compiled_combinations['combine_lime_anchors'] = sorted(combine_lime_anchors, key=lambda feature_value: compare_feature_weights(feature_value, priority_order))\n",
    "    \n",
    "    return compiled_combinations\n",
    "\n",
    "# 1st: get combinations between all the 3 explainers\n",
    "# 2nd: get combinations between 2 explainers\n",
    "#      decision between explainers will have\n",
    "#      priority -> 1 - anchors, 2 - shap, 3 - lime\n",
    "def combine_top_k_features(feature_names, json_out, k, priority_order, json_name):\n",
    "    final_explanations = dict()\n",
    "    # run each instance\n",
    "    for i in json_out:\n",
    "        combinations = combine_feature_explanations(feature_names, json_out[i], priority_order)\n",
    "        # 1st step of algorithm\n",
    "        # get combinations between all explainers\n",
    "        final_k_features = combinations['combine_all'][0:k]\n",
    "        # verify how many features misses to complete the x top features\n",
    "        missing_features = k - len(final_k_features)\n",
    "        \n",
    "        if missing_features:\n",
    "            # get x reamining features from each of combinations between 2 explainers\n",
    "            i_shap_lime_f = combinations['combine_shap_lime'][0:missing_features]\n",
    "            i_shap_anchors_f = combinations['combine_shap_anchors'][0:missing_features]\n",
    "            i_lime_anchors_f = combinations['combine_lime_anchors'][0:missing_features]\n",
    "            # concat lists\n",
    "            remaining_features = i_shap_lime_f+i_shap_anchors_f+i_lime_anchors_f\n",
    "            # 2st step of algorithm\n",
    "            # sort concatenated list\n",
    "            sorted_remaining_features = sorted(remaining_features, key=lambda feature_value: compare_feature_weights(feature_value, priority_order))\n",
    "            # concat features selected\n",
    "            final_k_features = final_k_features + sorted_remaining_features[0:missing_features]\n",
    "\n",
    "        instance_final_exp = dict()\n",
    "        instance_final_exp['forest_prediction_to_refactor'] = json_out[i]['forest_prediction']['refactor']\n",
    "        top_n_features_string = 'top_'+str(k)+'_features'\n",
    "        instance_final_exp[top_n_features_string] = final_k_features\n",
    "        \n",
    "        final_explanations[i] = instance_final_exp\n",
    "\n",
    "    #export explanations to json file\n",
    "    path = \"our_approach_jsons\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file_name = f\"{path}/our_top_{str(k)}_ranking_{json_name}.json\"\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        json.dump(final_explanations, outfile)\n",
    "        \n",
    "    return final_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "89661b8c-56b1-4e9b-a869-d6db9bcfadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_percentage(weight):\n",
    "    return round(weight*100, 1)\n",
    "    \n",
    "def get_top_k_features_from_approach(k, approach_exp, write_weight, write_agreement_index):\n",
    "    top_k_approach = [None] * k\n",
    "    k_approach = k if len(approach_exp) >= k else len(approach_exp)\n",
    "    for feature in range(0, k_approach):\n",
    "        exp_f = approach_exp[feature]\n",
    "        feature_name = exp_f[\"feature_name\"]\n",
    "        avg_weight = f\" ({get_round_percentage(exp_f[write_weight])}%\" if write_weight else \"\"\n",
    "        agreement_index = f\" - {get_round_percentage(exp_f[write_agreement_index])}%)\" if write_agreement_index else \")\"\n",
    "        top_k_approach[feature] = feature_name+avg_weight+agreement_index\n",
    "    return top_k_approach\n",
    "\n",
    "def generate_top_k_ranking_for_each_approach(k, our_approach_explanations, other_explanations, json_name):\n",
    "    general_top_k = dict()\n",
    "    \n",
    "    for i in our_approach_explanations:\n",
    "        top_k_each_instance = dict()\n",
    "\n",
    "        top_k_each_instance[\"forest_pred\"] = our_approach_explanations[i][\"forest_prediction_to_refactor\"]\n",
    "        top_k_each_instance[\"forest_pred\"] = our_approach_explanations[i][\"forest_prediction_to_refactor\"]\n",
    "        top_k_each_instance[\"our_approach\"] = get_top_k_features_from_approach(k, our_approach_explanations[i][\"top_5_features\"], \"avg_weight\", \"agreement_index\")\n",
    "        top_k_each_instance[\"shap_approach\"] = get_top_k_features_from_approach(k, other_explanations[i][\"shap\"][\"features\"], \"feature_weight\", 0)\n",
    "        top_k_each_instance[\"lime_approach\"] = get_top_k_features_from_approach(k, other_explanations[i][\"lime\"][\"features\"], \"feature_weight\", 0)\n",
    "        top_k_each_instance[\"anchors_approach\"] = get_top_k_features_from_approach(k, other_explanations[i][\"anchors\"][\"features\"], \"feature_weight\", 0)\n",
    "    \n",
    "        general_top_k[str(i)] = top_k_each_instance\n",
    "    #export explanations to json file\n",
    "    path = \"top_k_rankings_jsons\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file_name = f\"{path}/general_top_{str(k)}_ranking_{json_name}.json\"\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        json.dump(general_top_k, outfile)\n",
    "    return general_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a5840ec-eff4-49b3-bc65-73a53e271adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explanation_rankings_table(instance, df):\n",
    "    positions = ['<b>1</b>', '<b>2</b>', '<b>3</b>','<b>4</b>', '<b>5</b>']\n",
    "    rank_colors = ['#FFB0B0', '#FFC89F', '#FFF3A0', '#BEFF91', '#A8DDFF']\n",
    "    instance_info = f\"<b>Instance {instance} - {df.forest_pred[0]}</b>\"\n",
    "    \n",
    "    fig = go.Figure(data=[go.Table(\n",
    "      columnwidth = [200, 150,300],\n",
    "      header=dict(\n",
    "        values=[instance_info, \"<b>Rank Position</b>\", \"SHAP (weight)\", \"LIME (weight)\", \"Anchors(weight)\", \"Our Approach (weight - agreement index)\"],\n",
    "        line_color='darkslategray', fill_color='white',\n",
    "        align='center', font=dict(color='black', size=14)\n",
    "      ),\n",
    "      cells=dict(\n",
    "        values=[[], positions, df.shap_approach, df.lime_approach, df.anchors_approach, df.our_approach],\n",
    "        line_color='darkslategray', fill=dict(color=['white', rank_colors]),\n",
    "        align='center', font=dict(color='black', size=12)\n",
    "      ))\n",
    "    ])\n",
    "    # fig.show(renderer=\"png\", width=1150, height=500)\n",
    "    fig_formatted = fig.to_image(format=\"png\", width=1150, height=500, engine=\"kaleido\")\n",
    "    return fig_formatted\n",
    "\n",
    "def export_plot_explanation_rankings(top_k_rankings, pdf_name):\n",
    "    # if not os.path.exists(\"plot_images\"):\n",
    "    #     os.mkdir(\"plot_images\")\n",
    "    rankings_plots_img_bytes = []\n",
    "    for i in top_k_rankings:\n",
    "        rankings = pd.DataFrame(top_k_rankings[i])\n",
    "        plot_img_bytes = plot_explanation_rankings_table(i, rankings)\n",
    "        rankings_plots_img_bytes.append(plot_img_bytes)\n",
    "    \n",
    "    rankings_plots_pdf = img2pdf.convert(rankings_plots_img_bytes)\n",
    "    # save to pdf\n",
    "    path = \"top_k_rankings_pdfs\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    pdf_name = f\"{path}/{pdf_name}\"\n",
    "    with open(pdf_name, \"wb\") as file:\n",
    "        file.write(rankings_plots_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf6bc84-f107-4816-b67c-730c96964dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_data_and_indexes(dataset_name, id_column, target_column = 0):\n",
    "    # importing dataset\n",
    "    dataset = f\"datasets/{dataset_name}\"\n",
    "    data = pd.read_csv(dataset)\n",
    "    # getting dataset ids\n",
    "    data_indexes = data[id_column].to_list()\n",
    "    data = data.drop([target_column], axis=1) if target_column else data\n",
    "    data = data.set_index(id_column)\n",
    "    return data, data_indexes\n",
    "\n",
    "def export_top_k_ranking(k, priority_order, samples, samples_indexes, samples_name):\n",
    "    feature_names = list(samples.columns)\n",
    "    \n",
    "    other_explanations = export_other_explanations(samples, samples_indexes, samples_name)\n",
    "    \n",
    "    our_explanations = combine_top_k_features(feature_names, other_explanations, k, priority_order, samples_name)\n",
    "        \n",
    "    all_top_k_rankings = generate_top_k_ranking_for_each_approach(k, our_explanations, other_explanations, samples_name)\n",
    "    pdf_name = f\"{samples_name}_top_k_rankings.pdf\"\n",
    "    export_plot_explanation_rankings(all_top_k_rankings, pdf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704e2f84-190c-42e8-a1ec-83448aa08eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "priority_order = {0: {'explainer': 'rank_anchors', 'priority_weight': 3},\n",
    "         1: {'explainer': 'rank_shap', 'priority_weight': 2},\n",
    "         2: {'explainer': 'rank_lime', 'priority_weight': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a95f2f-5928-44fe-8bd4-11f17297db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_samples_by_category(cluster, samples_indexes):\n",
    "    negative_predict, predict_50_60, predict_60_90, predict_90 = ([] for i in range(4))\n",
    "    for i in range(0, len(cluster)):\n",
    "        predict = forest.predict_proba(cluster.iloc[[i]])[0][1]\n",
    "        if predict < 0.5:\n",
    "            negative_predict.append(samples_indexes[i])\n",
    "        elif predict >= 0.5 and predict < 0.6:\n",
    "            predict_50_60.append(samples_indexes[i])\n",
    "        elif predict >= 0.6 and predict < 0.9:\n",
    "            predict_60_90.append(samples_indexes[i])\n",
    "        elif predict >= 0.9:\n",
    "            predict_90.append(samples_indexes[i])\n",
    "    cluster = cluster.drop(negative_predict, axis=0)\n",
    "    # get 5 random samples from each group if there are more than 4 instances in the group\n",
    "    samples_predict_50_60 = random.sample(predict_50_60, 5) if len(predict_50_60) > 4 else predict_50_60\n",
    "    samples_predict_60_90 = random.sample(predict_60_90, 5) if len(predict_60_90) > 4 else predict_60_90\n",
    "    samples_predict_90 = random.sample(predict_90, 5) if len(predict_90) > 4 else predict_90\n",
    "    print(\"Negative predictions: \", len(negative_predict), \"\\nPredictions beetwen 0.5 and 0.6: \", len(predict_50_60), \"\\nPredictions beetwen 0.6 and 0.9: \", len(predict_60_90), \"\\nPredictions higher than 0.9: \", len(predict_90))\n",
    "    return [samples_predict_50_60, samples_predict_60_90, samples_predict_90]\n",
    "\n",
    "def concat_groups_of_samples(cluster, cluster_indexes):\n",
    "    samples_predict_50_60 = cluster.loc[cluster_indexes[0]]\n",
    "    samples_predict_60_90 = cluster.loc[cluster_indexes[1]]\n",
    "    samples_predict_90 = cluster.loc[cluster_indexes[2]]\n",
    "\n",
    "    samples_cluster = pd.concat([samples_predict_50_60, samples_predict_60_90, samples_predict_90])\n",
    "    simplified_cluster_indexes = np.concatenate(cluster_indexes)\n",
    "    return samples_cluster, simplified_cluster_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a235849-f83c-4efb-b7b8-adaeb05d8599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n"
     ]
    }
   ],
   "source": [
    "# importing cluster0 to explain\n",
    "cluster0, samples_indexes_cluster0 = get_formatted_data_and_indexes(\"2508_Cluster_00.csv\", \"id_\", \"cluster\")\n",
    "\n",
    "# importing cluster1 to explain\n",
    "cluster1, samples_indexes_cluster1 = get_formatted_data_and_indexes(\"2508_Cluster_01.csv\", \"id_\", \"cluster\")\n",
    "\n",
    "# separate 5 samples for each category:\n",
    "# G1 - RF prediction between 50 - 60%\n",
    "# G2 - RF prediction between 60 - 90%\n",
    "# G3 - RF prediction higher than 90%\n",
    "print(\"Cluster 0\")\n",
    "\n",
    "predict_90_c0 = []\n",
    "predict_90_c1 = []\n",
    "for i in range(0, len(cluster0)):\n",
    "    predict = forest.predict_proba(cluster0.iloc[[i]])[0][1]\n",
    "    if predict >= 0.9:\n",
    "        predict_90_c0.append(samples_indexes_cluster0[i])\n",
    "\n",
    "for i in range(0, len(cluster1)):\n",
    "    predict = forest.predict_proba(cluster1.iloc[[i]])[0][1]\n",
    "    if predict >= 0.9:\n",
    "        predict_90_c1.append(samples_indexes_cluster1[i])\n",
    "# get 5 random samples from each group if there are more than 4 instances in the group\n",
    "samples_predict_90_c0 = random.sample(predict_90_c0, 1000) if len(predict_90_c0) > 1000 else predict_90_c0\n",
    "samples_predict_90_c1 = random.sample(predict_90_c1, 1000) if len(predict_90_c1) > 1000 else predict_90_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54fa8be5-2b99-4a79-a8dd-7d4416b6e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predict_90_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03860756-1db0-4475-93e7-c73e8bf54d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_1k_c0 =  cluster0.filter(items=samples_predict_90_c0, axis=0)\n",
    "\n",
    "samples_1k_c1 =  cluster1.filter(items=samples_predict_90_c1, axis=0)\n",
    "\n",
    "samples_1k_c0.to_csv(path_datasets+\"1k_samples_cluster0.csv\")\n",
    "samples_1k_c1.to_csv(path_datasets+\"1k_samples_cluster1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abdb9ed5-2f26-4610-b530-480ea32508e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "Negative predictions:  7 \n",
      "Predictions beetwen 0.5 and 0.6:  6 \n",
      "Predictions beetwen 0.6 and 0.9:  19 \n",
      "Predictions higher than 0.9:  8\n",
      "Cluster 2\n",
      "Negative predictions:  0 \n",
      "Predictions beetwen 0.5 and 0.6:  1 \n",
      "Predictions beetwen 0.6 and 0.9:  17 \n",
      "Predictions higher than 0.9:  22\n",
      "Intercept 0.4873605783948534\n",
      "Prediction_local [0.66259933]\n",
      "Right: 0.55\n",
      "Intercept 0.5011840383945643\n",
      "Prediction_local [0.53962802]\n",
      "Right: 0.55\n",
      "Intercept 0.5805355663314902\n",
      "Prediction_local [0.50627134]\n",
      "Right: 0.5\n",
      "Intercept 0.580889011377583\n",
      "Prediction_local [0.5631048]\n",
      "Right: 0.57\n",
      "Intercept 0.5139634819292395\n",
      "Prediction_local [0.46446561]\n",
      "Right: 0.5467738095238095\n",
      "Intercept 0.3955775689243477\n",
      "Prediction_local [0.6840591]\n",
      "Right: 0.85\n",
      "Intercept 0.34645695009832767\n",
      "Prediction_local [0.64117838]\n",
      "Right: 0.82\n",
      "Intercept 0.4871383177114124\n",
      "Prediction_local [0.65026648]\n",
      "Right: 0.84\n",
      "Intercept 0.4484494604250755\n",
      "Prediction_local [0.6333454]\n",
      "Right: 0.8\n",
      "Intercept 0.49527831497094865\n",
      "Prediction_local [0.61050714]\n",
      "Right: 0.67\n",
      "Intercept 0.5055960457774928\n",
      "Prediction_local [0.57736538]\n",
      "Right: 0.91\n",
      "Intercept 0.47123925327538685\n",
      "Prediction_local [0.63504034]\n",
      "Right: 0.91\n",
      "Intercept 0.5198331606377778\n",
      "Prediction_local [0.67513067]\n",
      "Right: 0.91\n",
      "Intercept 0.41659183071044825\n",
      "Prediction_local [0.75153527]\n",
      "Right: 0.94\n",
      "Intercept 0.42479291407056863\n",
      "Prediction_local [0.72174723]\n",
      "Right: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 0.5111475532963863\n",
      "Prediction_local [0.43521769]\n",
      "Right: 0.54\n",
      "Intercept 0.4801548129215474\n",
      "Prediction_local [0.68868692]\n",
      "Right: 0.79\n",
      "Intercept 0.5908405492018381\n",
      "Prediction_local [0.35192735]\n",
      "Right: 0.89\n",
      "Intercept 0.4996928032376775\n",
      "Prediction_local [0.40872862]\n",
      "Right: 0.66\n",
      "Intercept 0.5102312900310897\n",
      "Prediction_local [0.44313599]\n",
      "Right: 0.85\n",
      "Intercept 0.6424519892419184\n",
      "Prediction_local [0.39099917]\n",
      "Right: 0.67\n",
      "Intercept 0.5182696017299134\n",
      "Prediction_local [0.61402753]\n",
      "Right: 0.95\n",
      "Intercept 0.3887838645608035\n",
      "Prediction_local [0.65537357]\n",
      "Right: 0.94\n",
      "Intercept 0.5141669132478637\n",
      "Prediction_local [0.60722474]\n",
      "Right: 0.97\n",
      "Intercept 0.44089715621806497\n",
      "Prediction_local [0.64206169]\n",
      "Right: 0.94\n",
      "Intercept 0.44847884602807886\n",
      "Prediction_local [0.61163908]\n",
      "Right: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    }
   ],
   "source": [
    "# importing cluster0 to explain\n",
    "cluster0, samples_indexes_cluster0 = get_formatted_data_and_indexes(\"Cluster_00.csv\", \"id_\", \"cluster\")\n",
    "\n",
    "# importing cluster2 to explain\n",
    "cluster2, samples_indexes_cluster2 = get_formatted_data_and_indexes(\"Cluster_02.csv\", \"id_\", \"cluster\")\n",
    "\n",
    "# separate 5 samples for each category:\n",
    "# G1 - RF prediction between 50 - 60%\n",
    "# G2 - RF prediction between 60 - 90%\n",
    "# G3 - RF prediction higher than 90%\n",
    "print(\"Cluster 0\")\n",
    "samples_indexes_cluster0 = separate_samples_by_category(cluster0, samples_indexes_cluster0)\n",
    "print(\"Cluster 2\")\n",
    "samples_indexes_cluster2 = separate_samples_by_category(cluster2, samples_indexes_cluster2)\n",
    "\n",
    "# concat samples in 1 dataframe to group the result in one pdf\n",
    "samples_cluster0, simplified_indexes_cluster0 = concat_groups_of_samples(cluster0, samples_indexes_cluster0)\n",
    "samples_cluster2, simplified_indexes_cluster2 = concat_groups_of_samples(cluster2, samples_indexes_cluster2)\n",
    "\n",
    "export_top_k_ranking(k, priority_order, samples_cluster0, simplified_indexes_cluster0, \"cluster0\")\n",
    "export_top_k_ranking(k, priority_order, samples_cluster2, simplified_indexes_cluster2, \"cluster2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ff2cc136-e39e-425c-b612-5b70e9e75074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 0.4283444302279355\n",
      "Prediction_local [0.71331141]\n",
      "Right: 0.9\n",
      "Intercept 0.46961365883432077\n",
      "Prediction_local [0.71598881]\n",
      "Right: 0.91\n",
      "Intercept 0.49597561251144723\n",
      "Prediction_local [0.69204529]\n",
      "Right: 0.96\n",
      "Intercept 0.5044314747303343\n",
      "Prediction_local [0.42422714]\n",
      "Right: 0.83\n",
      "Intercept 0.48655327051639125\n",
      "Prediction_local [0.56694038]\n",
      "Right: 0.95\n",
      "Intercept 0.60623600150518\n",
      "Prediction_local [0.4124607]\n",
      "Right: 0.85\n",
      "Intercept 0.5446801214617696\n",
      "Prediction_local [0.67464846]\n",
      "Right: 0.97\n",
      "Intercept 0.4301668382291035\n",
      "Prediction_local [0.61977351]\n",
      "Right: 0.78\n",
      "Intercept 0.4782421999773504\n",
      "Prediction_local [0.77996678]\n",
      "Right: 0.99\n",
      "Intercept 0.5632574073576998\n",
      "Prediction_local [0.39995814]\n",
      "Right: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    }
   ],
   "source": [
    "samples_10_positive, samples_indexes_10_positive = get_formatted_data_and_indexes(\"Amostra-Dataset.csv\", \"id_\")\n",
    "export_top_k_ranking(k, priority_order, samples_10_positive, samples_indexes_10_positive, \"10_positive_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d4229c5-d55a-427c-8287-ab2ae2e7c469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 0.5478211902906257\n",
      "Prediction_local [0.3536736]\n",
      "Right: 0.15\n",
      "Intercept 0.5419000555025999\n",
      "Prediction_local [0.59292239]\n",
      "Right: 0.31\n",
      "Intercept 0.5775078880574468\n",
      "Prediction_local [0.61488386]\n",
      "Right: 0.35\n",
      "Intercept 0.394180076931551\n",
      "Prediction_local [0.58218739]\n",
      "Right: 0.24\n",
      "Intercept 0.5819128607954254\n",
      "Prediction_local [0.49768791]\n",
      "Right: 0.11\n",
      "Intercept 0.5803049216510627\n",
      "Prediction_local [0.34458158]\n",
      "Right: 0.21\n",
      "Intercept 0.5106273523682839\n",
      "Prediction_local [0.57039349]\n",
      "Right: 0.3\n",
      "Intercept 0.45532283855038824\n",
      "Prediction_local [0.69966663]\n",
      "Right: 0.26\n",
      "Intercept 0.4911524017628196\n",
      "Prediction_local [0.73836011]\n",
      "Right: 0.34\n",
      "Intercept 0.513922246706817\n",
      "Prediction_local [0.65912291]\n",
      "Right: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    }
   ],
   "source": [
    "samples_10_negative, samples_indexes_10_negative = get_formatted_data_and_indexes(\"NO_instances.csv\", \"id\")\n",
    "export_top_k_ranking(k, priority_order, samples_10_negative, samples_indexes_10_negative, \"10_negative_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78d54eae-37bc-4e3f-b6f3-cc525552567d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 0.46466891562838364\n",
      "Prediction_local [0.56270333]\n",
      "Right: 0.72\n",
      "Intercept 0.5142386962319422\n",
      "Prediction_local [0.37979484]\n",
      "Right: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 0.5454733159597056\n",
      "Prediction_local [0.40637346]\n",
      "Right: 0.07\n",
      "Intercept 0.48359576627695067\n",
      "Prediction_local [0.7458437]\n",
      "Right: 0.91\n",
      "Intercept 0.5608347848885814\n",
      "Prediction_local [0.37889312]\n",
      "Right: 0.13\n",
      "Intercept 0.5016704640957175\n",
      "Prediction_local [0.5886479]\n",
      "Right: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    }
   ],
   "source": [
    "samples_yes_experiment, indexes_yes_experiment = get_formatted_data_and_indexes(\"Yes_Instances_Experiment.csv\", \"id\", \"y\")\n",
    "export_top_k_ranking(k, priority_order, samples_yes_experiment, indexes_yes_experiment, \"yes_experiment\")\n",
    "\n",
    "samples_no_experiment, indexes_no_experiment = get_formatted_data_and_indexes(\"No_Instances_Experiment.csv\", \"id\", \"Y\")\n",
    "export_top_k_ranking(k, priority_order, samples_no_experiment, indexes_no_experiment, \"no_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3a4cf-bf65-487e-9530-4b0d16c2ca7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
